{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import csv\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics \n",
    "from scipy import stats\n",
    "import io\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Importing files from github for google colab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-f3d9925c4710>:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  rules_df  = pd.read_csv(url, sep='delimiter',header=None)\n",
      "<ipython-input-8-f3d9925c4710>:4: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  frequency_df= pd.read_csv(url2, sep='delimiter',header=None)\n",
      "<ipython-input-8-f3d9925c4710>:6: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  V_prevalence_df =pd.read_csv(url3, sep='delimiter',header=None)\n",
      "<ipython-input-8-f3d9925c4710>:8: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  population_df=pd.read_csv(url4, sep='delimiter',header=None)\n"
     ]
    }
   ],
   "source": [
    "url = 'https://raw.githubusercontent.com/sobhan-moosavi/varicella_study/main/contact_rules.csv'\n",
    "rules_df  = pd.read_csv(url, sep='delimiter',header=None)\n",
    "url2='https://raw.githubusercontent.com/sobhan-moosavi/varicella_study/main/frequency_contact.csv'\n",
    "frequency_df= pd.read_csv(url2, sep='delimiter',header=None)\n",
    "url3='https://raw.githubusercontent.com/sobhan-moosavi/varicella_study/main/varicella_prevalance.csv'\n",
    "V_prevalence_df =pd.read_csv(url3, sep='delimiter',header=None)\n",
    "url4='https://raw.githubusercontent.com/sobhan-moosavi/varicella_study/main/population.csv'\n",
    "population_df=pd.read_csv(url4, sep='delimiter',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *importing files from pc\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "frequency_df = pd.read_csv('frequency_contact.csv')\n",
    "population_df = pd.read_csv('population.csv')\n",
    "V_prevalence_df = pd.read_csv('varicella_prevalance.csv')\n",
    "rules_df = pd.read_csv('contact_rules.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE GRAPH CONTROL PANEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N =300  # Number of nodes\n",
    "setting='home'    #the setting we are evaluating(home,work,school,other)\n",
    "D=10#number of days the model runs\n",
    "increase_rate=.5 #the rate of increasing weight per contact\n",
    "lower_weight=0  #the minimum weight between two node\n",
    "threshold_n=1     #threshold of product weight two nodes with same neighbor for increasing weight\n",
    "increse_rate_n=0  #increse rate weight for two nodes with same neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-Defining Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8f66ede015c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mavailable_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mgroup_popularity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_fallback_to_positional\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "#defining a dictionary of nodes\n",
    "available_groups  = [] #16_age_groups\n",
    "group_popularity = [] #based on consensus year 95\n",
    "v_prevalence=dict() #based on meta analysis(data is not exact!! update needed!!)contan(age_group,prevalance,lower CL)\n",
    "nodes_dic=dict()\n",
    "\n",
    "\n",
    "for i, row in population_df.iterrows():\n",
    "    available_groups.append(row[0])\n",
    "    group_popularity.append(float(row[1]))\n",
    "    \n",
    "\n",
    "for i, row in V_prevalence_df.iterrows():\n",
    "    v_prevalence[row[0]]=[float(row[1]),float(row[2])]\n",
    "                    \n",
    "for i in range(N):\n",
    "    while True:\n",
    "        r=random.random()\n",
    "        t=random.randint(0,15)\n",
    "        if r<=group_popularity[t]:\n",
    "            nodes_dic[f'n{i+1}']={'age':available_groups[t]}\n",
    "            break\n",
    "\n",
    "\n",
    "for i in range(N):\n",
    "    a=v_prevalence[nodes_dic[f'n{i+1}']['age']][0]\n",
    "    b=v_prevalence[nodes_dic[f'n{i+1}']['age']][1]\n",
    "    r=np.random.random()\n",
    "    t=np.random.normal(a,(a-b)) \n",
    "    if r<=t:\n",
    "        nodes_dic[f'n{i+1}']['infection']=1\n",
    "    else:\n",
    "        nodes_dic[f'n{i+1}']['infection']=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data for frequency of contact in each setting for comparison\n",
    "frequency=dict()\n",
    "\n",
    "for i, row in frequency_df.iterrows():\n",
    "    frequency[row[0]]=dict()\n",
    "    for i in range(1,6):\n",
    "        frequency[row[0]][i]=float(row[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Which `group` each node belongs to?\n",
    "\n",
    "* We  used `Age specific population for Iran` to define probability of each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# let's see the number of nodes in each group:\n",
    "\n",
    "age_count = {}\n",
    "for n in nodes_dic.keys():\n",
    "    \n",
    "    if nodes_dic[n]['age'] in age_count:\n",
    "        age_count[nodes_dic[n]['age']] = age_count[nodes_dic[n]['age']] + 1\n",
    "    else:\n",
    "        age_count[nodes_dic[n]['age']] = 1\n",
    "age_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Defining Connection Rules between Node Groups\n",
    "\n",
    "### `We define rules in terms of connection probability between each two groups`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing rules from .csv to nested dictionary\n",
    "rules={}  # rules contain ->{location:{contactor:{contactee:contact number}\n",
    "temp_0={}\n",
    "temp_1={}\n",
    "location=[]\n",
    "contactor=[]\n",
    "contactee=[]\n",
    "contact_number=[]\n",
    "\n",
    "for i, row in rules_df.iterrows():\n",
    "    \n",
    "    location.append(row[0])\n",
    "    contactor.append(row[1])\n",
    "    contactee.append(row[2])\n",
    "    contact_number.append(float(row[3]))\n",
    "\n",
    "for o in range (0,1280,256):\n",
    "    for m in range(o,o+256,16):\n",
    "        for n in range (m,m+16):\n",
    "            \n",
    "            temp_0[contactee[n]]=contact_number[n]\n",
    "        temp_1[contactor[m]]=temp_0.copy()\n",
    "    rules[location[o]]=temp_1.copy()     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3- Visualization for `SMALL` graph\n",
    "\n",
    "### ⚠️ Only for SMALL graphs (i.e. noes < 100)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=500, node_color='red', alpha=0.7)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos, width=1, alpha=0.2, edge_color=\"b\", style=\"-\")\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.margins(0.08)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-Defining Rules to Connecting Nodes and Adjusting `Probabilities/Distances`\n",
    "\n",
    "* This would be the step that our Naive graph would evolve over the time through a simulation process\n",
    "* we monitor connection between nodes and update weights based on connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in this block we've defiend a function \"Run\" \n",
    "def Run(increase_rate,threshold_n,increse_rate_n,D):\n",
    "    \n",
    "    #building the graph based on nodes_dic\n",
    "    \n",
    "    for i in nodes_dic.keys():\n",
    "        for j in nodes_dic.keys():\n",
    "            if i!=j and rules[setting][nodes_dic[i]['age']][nodes_dic[j][\"age\"]]!=0:\n",
    "               #this condition determine if a node is added to graph or not based on setting \n",
    "                G.add_edge(i,j,weight=1)\n",
    "     #counting number of each age group in graph  \n",
    "    group_count = {}\n",
    "    for n in nx.nodes(G):\n",
    "    \n",
    "        if nodes_dic[n]['age'] in group_count:\n",
    "            group_count[nodes_dic[n]['age']] = group_count[nodes_dic[n]['age']] + 1\n",
    "        else:\n",
    "            group_count[nodes_dic[n]['age']] = 1\n",
    "            \n",
    "            \n",
    "    \n",
    "    #bulding empty dictinary \"contacted\" for storing contacts in single day\n",
    "    #building empty dictionary for monitoring all contacts during all days\n",
    "    #building empty dictionary for monitoring all weights during all days\n",
    "    contacted={}\n",
    "    contacted_all={}\n",
    "    weight_all={} \n",
    "    \n",
    "    for i in nx.edges(G):\n",
    "        \n",
    "        if i[0] in contacted_all.keys():\n",
    "            contacted[i[0]][i[1]]=0\n",
    "            contacted_all[i[0]][i[1]]=[]\n",
    "            weight_all[i[0]][i[1]]=[]\n",
    "                 \n",
    "        else :\n",
    "            contacted[i[0]]={i[1]:0}\n",
    "            contacted_all[i[0]]={i[1]:[]}\n",
    "            weight_all[i[0]]={i[1]:[]}\n",
    "            \n",
    "        \n",
    "        \n",
    "            \n",
    "    \n",
    "    for d in range (0,D):#we are running the model for D days\n",
    "        \n",
    "        #building a dictionary that includes number of 'weight addition' and number of nodes viable for 'weight substraction'\n",
    "        N_contacted=dict()\n",
    "        for i in nx.nodes(G):\n",
    "            N_contacted[i]={}\n",
    "            for j in group_count.keys():\n",
    "                N_contacted[i][j]={'N_base':0,'N_c':0,'decrease_rate':0 }\n",
    "                               \n",
    "        #iterating thorough the graph and storing connections in 'contacted'\n",
    "        for i in nx.edges(G):\n",
    "                                   \n",
    "            age_p=rules[setting][nodes_dic[i[0]]['age']][nodes_dic[i[1]][\"age\"]]\n",
    "            r=random.random()\n",
    "            \n",
    "            if r <(age_p/group_count[nodes_dic[i[1]]['age']])*G.edges[i[0],i[1]]['weight']:\n",
    "                contacted[i[0]][i[1]]=1\n",
    "                contacted_all[i[0]][i[1]].append(1)#storing contacts of each run in this dic\n",
    "              \n",
    "            else:\n",
    "                contacted[i[0]][i[1]]=0\n",
    "                contacted_all[i[0]][i[1]].append(0)\n",
    "                               \n",
    "        # iterating thorough 'contacted' and updating the weights based on it\n",
    "        for i in nx.edges(G):\n",
    "            \n",
    "            age_p=rules[setting][nodes_dic[i[0]]['age']][nodes_dic[i[1]][\"age\"]]\n",
    "            \n",
    "            upper_weight=1/age_p*(group_count[nodes_dic[i[1]]['age']]-age_p)\n",
    "           \n",
    "            if contacted[i[0]][i[1]]==1 and G[i[0]][i[1]]['weight']*(1+increase_rate)<upper_weight:\n",
    "                #we don't want the weight to be more than 'upper weight'\n",
    "\n",
    "                t=G[i[0]][i[1]]['weight']+increase_rate\n",
    "                G.add_edge(i[0],i[1],weight=t)\n",
    "                N_contacted[i[0]][nodes_dic[i[1]]['age']]['N_c']+=1\n",
    "            if G[i[0]][i[1]]['weight']-N_contacted[i[0]][nodes_dic[i[1]]['age']]['decrease_rate']<lower_weight:\n",
    "                N_contacted[i[0]][nodes_dic[i[1]]['age']]['N_base']+=1\n",
    "         \n",
    "        #we calculate how much weight is added overall,and then distrubt it between all nodes that should decrease weight\n",
    "        for i in nx.edges(G):\n",
    "            \n",
    "            N_base= N_contacted[i[0]][nodes_dic[i[1]]['age']]['N_base']\n",
    "            N_c=N_contacted[i[0]][nodes_dic[i[1]]['age']]['N_c']\n",
    "            age_p=rules[setting][nodes_dic[i[0]]['age']][nodes_dic[i[1]][\"age\"]]\n",
    "            pop=group_count[nodes_dic[i[1]]['age']]-N_base-N_c\n",
    "            if pop!=0:\n",
    "                N_contacted[i[0]][nodes_dic[i[1]]['age']]['decrease_rate']=(increase_rate*N_c)/pop\n",
    "            else:\n",
    "                N_contacted[i[0]][nodes_dic[i[1]]['age']]['decrease_rate']=0\n",
    "            \n",
    "            if contacted[i[0]][i[1]]==0 and (G[i[0]][i[1]]['weight']-N_contacted[i[0]][nodes_dic[i[1]]['age']]['decrease_rate'] >lower_weight):\n",
    "                #we don't want the weight to be lower than lower_weight\n",
    "                t=G[i[0]][i[1]]['weight']-N_contacted[i[0]][nodes_dic[i[1]]['age']]['decrease_rate']\n",
    "                G.add_edge(i[0],i[1],weight=t)\n",
    "            weight_all[i[0]][i[1]].append(G.edges[i[0],i[1]]['weight'])\n",
    "\n",
    "        #updating weight between two nodes with same neighbor\n",
    "        #for i in nodes_dic.keys():\n",
    "            #for j in nodes_dic.keys():\n",
    "                #if i!=j:\n",
    "                    #for o in nodes_dic.keys():\n",
    "                        #if o!=j and o!=i:\n",
    "\n",
    "                            #if (G[i][o]['weight']*G[i][j]['weight'])>threshold_n and G[o][j]['weight']<1:\n",
    "                                #t=G[o][j]['weight']+increse_rate_n\n",
    "                                #G.add_edge(i,j,weight=t)\n",
    "    return(contacted_all,G,weight_all,group_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the graph after the updates"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# nodes\n",
    "nx.draw_networkx_nodes(G, pos, node_size=500, node_color='red', alpha=0.7)\n",
    "\n",
    "# edges\n",
    "nx.draw_networkx_edges(G, pos, width=1, alpha=0.2, edge_color=\"b\", style=\"-\")\n",
    "\n",
    "# labels\n",
    "nx.draw_networkx_labels(G, pos, font_size=10, font_family=\"sans-serif\")\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.margins(0.08)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5- Monitroing the graph\n",
    "### we monitor the graph for age specific number of contact per day and frequeny of contact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns p_value wilcoxon for comparison age stratified number of contacts \n",
    "   \n",
    "\n",
    "def metric_A_wilx(results) :   \n",
    "\n",
    "    contacted_all=results[0]\n",
    "    G=results[1]\n",
    "    group_count=results[3]\n",
    "\n",
    "    L1=[]\n",
    "    L2=[]\n",
    "\n",
    "    rules_m=dict()\n",
    "    rules_m[setting]=dict()\n",
    "\n",
    "    for i in rules[setting].keys():\n",
    "        rules_m[setting][i]=dict()\n",
    "        for j in rules[setting][i].keys():\n",
    "             rules_m[setting][i][j]=0\n",
    "\n",
    "\n",
    "    for i in nx.edges(G):\n",
    "        t=statistics.mean(contacted_all[i[0]][i[1]])/(group_count[nodes_dic[i[0]]['age']])\n",
    "        rules_m[setting][nodes_dic[i[0]]['age']][nodes_dic[i[1]]['age']]+=t\n",
    "   \n",
    "    for i in rules_m[setting].keys():\n",
    "        for j in rules_m[setting][i].keys():\n",
    "            L1.append(rules[setting][i][j])\n",
    "            L2.append(rules_m[setting][i][j])\n",
    "\n",
    "    I=stats.wilcoxon(L1,L2, zero_method='wilcox', correction=False, alternative='two-sided', mode='auto')\n",
    "    return(I,rules_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function returns the absoloute error for age stratified number of contact\n",
    "\n",
    "def metric_A_abs(results):\n",
    "    \n",
    "    L=[]\n",
    "\n",
    "    contacted_all=results[0]\n",
    "    G=results[1]\n",
    "    group_count=results[3]\n",
    "\n",
    "    rules_m=dict()\n",
    "    rules_m[setting]=dict()\n",
    "\n",
    "    for i in rules[setting].keys():\n",
    "        rules_m[setting][i]=dict()\n",
    "        for j in rules[setting][i].keys():\n",
    "             rules_m[setting][i][j]=0\n",
    "\n",
    "\n",
    "    for i in nx.edges(G):\n",
    "        \n",
    "        t=statistics.mean(contacted_all[i[0]][i[1]])/(group_count[nodes_dic[i[0]]['age']])\n",
    "        rules_m[setting][nodes_dic[i[0]]['age']][nodes_dic[i[1]]['age']]+=t\n",
    "\n",
    "    for i in rules_m[setting].keys():\n",
    "        for j in rules_m[setting][i].keys():\n",
    "\n",
    "                L.append(abs((rules_m[setting][i][j])-(rules[setting][i][j])))\n",
    "\n",
    "    I=statistics.mean(L)\n",
    "    return(I,rules_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that returns mean absoloute error 'frequency of contacts ' in the last x day of model\n",
    "def metric_F(results):\n",
    "    \n",
    "    n=0\n",
    "    \n",
    "    \n",
    "    contacted_all=results[0]\n",
    "    G=results[1]\n",
    "    group_count=results[3]\n",
    "    \n",
    "    L1=[]\n",
    "    L2=[]\n",
    "    \n",
    "    frequency_m=dict()\n",
    "    for i in frequency.keys():\n",
    "        frequency_m[i]={1:0,2:0,3:0,4:0,5:0}\n",
    "\n",
    "    for i in contacted_all.keys():\n",
    "        for j in contacted_all[i].keys():\n",
    "            if contacted_all[i][j][-1]==1:\n",
    "                \n",
    "                age_p=rules[setting][nodes_dic[i]['age']][nodes_dic[j][\"age\"]]\n",
    "        \n",
    "                t=(age_p/group_count[nodes_dic[i]['age']])*G.edges[i,j]['weight']\n",
    "\n",
    "                n+=1\n",
    "\n",
    "                if sum(contacted_all[i][j])>1 and t<(1/30) :\n",
    "                    frequency_m[setting][4]+=1\n",
    "\n",
    "                elif t>=(1/30) and t<=(2/30):\n",
    "                    frequency_m[setting][3]+=1\n",
    "\n",
    "                elif t>(2/30) and t <=(2/7):\n",
    "                    frequency_m[setting][2]+=1\n",
    "\n",
    "                elif t>(2/7):\n",
    "\n",
    "                    frequency_m[setting][1]+=1\n",
    "                else:\n",
    "                    frequency_m[setting][5]+=1\n",
    "\n",
    "    for i in frequency_m[setting].keys():\n",
    "        if n!=0:\n",
    "        \n",
    "            frequency_m[setting][i]=frequency_m[setting][i]/n\n",
    "        if n==0:\n",
    "            \n",
    "            frequency_m[setting][i]=0\n",
    "        \n",
    "            \n",
    "        \n",
    "    \n",
    "    for i in frequency_m[setting].keys():\n",
    "        \n",
    "        L1.append(frequency[setting][i])\n",
    "        L2.append(frequency_m[setting][i])\n",
    "        \n",
    "    \n",
    "    I=stats.wilcoxon(L1,L2, zero_method='wilcox', correction=False, alternative='two-sided', mode='auto')\n",
    "    #print('for the first time:',frequency_m[setting][5],'\\nless than once a month:',frequency_m[setting][4],'\\nabout once or twice a month:',frequency_m[setting][3],'\\nabout once or twice a week',frequency_m[setting][2],'\\ndaily or almost daily',frequency_m[setting][1])\n",
    "\n",
    "    return(I,frequency_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluating results\n",
    "### this part of code evaluates results of  function Run for the inputs\n",
    "\n",
    "###### Run -> input : increase_rate, threshold_n, increse_rate_n, D \n",
    "###### Run -> output : contacted_all, G, weight_all, group_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part returns the absoloute error for age stratified number of contact\n",
    "results=Run(increase_rate,threshold_n,increse_rate_n,D )\n",
    "M_abs=metric_A_abs(results)\n",
    "print(M_abs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part shows number of age stratified contact from data and model for comparision\n",
    "for i in rules[setting].keys():\n",
    "    for j in rules[setting].keys():\n",
    "        print(i,'->',j,M_abs[1][setting][i][j],'//',rules[setting][i][j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this part returns p_value wilcoxon for comparison age stratified number of contacts \n",
    "\n",
    "print('%f' % metric_A_wilx(results)[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this shows the mean of all edeges across the graph(it's supposed to stay close to one)\n",
    "mean_weights=[]\n",
    "for i in nx.edges(results[1]):\n",
    "             \n",
    "    mean_weights.append(results[1].edges[i[0],i[1]]['weight'])\n",
    "            \n",
    "print(statistics.mean(mean_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this shows the fitting for frequency\n",
    "results_F=metric_F(results)[1]\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "\n",
    "for i in results_F[setting].keys():\n",
    "    print (setting,':',i,'//',results_F[setting][i],'//',frequency[setting][i])\n",
    "    plt.plot(i,results_F[setting][i],'+r',linewidth=1, markersize=12,alpha=1)\n",
    "    plt.plot(i,frequency[setting][i],'+b',linewidth=1, markersize=12,alpha=1)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this figure shows evoloution of weights thorough time\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "for i in nx.edges(results[1]):\n",
    "    \n",
    "    plt.plot(range(0,D),results[2][i[0]][i[1]],'k.',linewidth=.01, markersize=.5,alpha=.1)\n",
    "plt.xlabel(\"days\")\n",
    "plt.ylabel('weight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_final={0:[],60:[],120:[],180:[],240:[],300:[],359:[]}\n",
    "for v in weight_final.keys():\n",
    "    for i in nx.edges(results[1]):\n",
    "        \n",
    "        weight_final[v].append(results[2][i[0]][i[1]][v])\n",
    "\n",
    "for i in reversed(weight_final.keys()):\n",
    "    plt.hist(weight_final[i],bins=20)\n",
    "plt.axis([0,50,0,80000])\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "plt.hist(weight_final[359],bins=100)\n",
    "plt.axis([0,50,0,20000])\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel('frequency')\n",
    "plt.show()\n",
    "plt.hist(weight_final[359],bins=100)\n",
    "plt.xlabel(\"weight\")\n",
    "plt.ylabel('frequency')\n",
    "plt.axis([0,50,0,1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
